{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4 Analyzing and visualizing PM2.5 data streams (Step-3)\n",
    "\n",
    "This Jupyter notebook represents a **Kafka consumer** that analyses the data stream generated in the previous step. We will perform two types of analysis:\n",
    "\n",
    "**a) Monitoring:** Creating a map visualization of the streamed data in \"near real-time\"\n",
    "\n",
    "**b) Event Detection:** Calculation of the 3-day mean value of PM2.5 concentrations for each location. If the mean exceeds a critical value (event of interest), we trigger a notification. The threshold value is defined later in this Notebook document and can be changed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Libraries\n",
    "\n",
    "import warnings ## ignore warnings that might be shown due to older python libraries\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "import geopandas as gpd # to read files with spatial information like raster or vector\n",
    "import json, math # handle json and mathematical operations\n",
    "import numpy as np # handle matrix type operations and manipulation on numerical data\n",
    "import geojson # handle json files with spatial information \n",
    "import pandas as pd # handle tabular data\n",
    "import sys # output error messages\n",
    "import time # provides time related functions\n",
    "import socket #  to get network properties for kafka communication\n",
    "from confluent_kafka import Consumer, KafkaError, KafkaException # Kafka library for kafka consumer components\n",
    "\n",
    "from ipyleaflet import Map, basemaps, WidgetControl, Marker, basemap_to_tiles, DrawControl, GeoJSON, MarkerCluster, AwesomeIcon # widget to enable map interactions\n",
    "from ipywidgets import IntSlider, ColorPicker, jslink # widget to enable map interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KAFKA CONSUMER DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START: AVOID MAKING CHANGES ###\n",
    "\n",
    "'''\n",
    "Offset decides in what order to consume the message. \"smallest\" means read the first message that was sent at 1st position and then the others.\n",
    "\"largest\" will mean to read the most 'recent' message in 1st position and then others in the same order\n",
    "'''\n",
    "\n",
    "conf = {'bootstrap.servers': 'kafka:9093',\n",
    "        'default.topic.config': {'auto.offset.reset': 'smallest'},\n",
    "        'group.id': socket.gethostname()}\n",
    "\n",
    "### END: AVOID MAKING CHANGES ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set topic name as set in file: step_2_producer.ipynb\n",
    "topic = \"pm25_stream\"\n",
    "\n",
    "## Kafka streamed data will be stored here\n",
    "df = pd.DataFrame(columns=['lat','lon','value','day','boxId'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise the consumer and subscribe to the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer = Consumer(conf)\n",
    "consumer.subscribe([topic])\n",
    "\n",
    "running = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions and variables that will be used for real-time processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the PM Threshold\n",
    "pm_threshold = 20\n",
    "\n",
    "def warning_event_response(timestamp, pm, sensebox):\n",
    "\n",
    "    '''\n",
    "    This function defines what actions should be performed when the PM 2.5 levels have exceeded the defined threshold above\n",
    "    In this case we are simply printing a message\n",
    "    '''\n",
    "    \n",
    "    return str(sensebox)+\" : \"+str(timestamp)+\" : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of \"+str(pm)\n",
    "\n",
    "    '''\n",
    "    You can insert an email trigger script after this comment\n",
    "    '''\n",
    "    \n",
    "def event_notification(df, pm_threshold):\n",
    "    \n",
    "    '''\n",
    "    Function to handle event notifications in real-time. This function is used to define the operations that should be \n",
    "    triggered for every data point that is received by the consumer.\n",
    "    '''\n",
    "    \n",
    "    try:\n",
    "                \n",
    "        ## Get rolling average of pm value by lat/lon over last 3 days\n",
    "        rolling_average = df.groupby(['lat','lon']).rolling(3)['value'].mean().reset_index()\n",
    "        rolling_average.dropna(inplace=True)\n",
    "        \n",
    "        current_lat = df.iloc[df.shape[0] - 1,:].lat\n",
    "        current_lon = df.iloc[df.shape[0] - 1,:].lon\n",
    "        \n",
    "        ## Get the rolling average value for each unique lat/lon. This is required because the stream has data for multiple locations\n",
    "        rolling_average_index = rolling_average[(rolling_average['lat'] == current_lat) & (rolling_average['lon'] == current_lon)].index[-1]\n",
    "        \n",
    "        ## Get the details for the pm value, time and senseboxid for the current lat/lon that was received\n",
    "        pm_value = rolling_average.loc[rolling_average_index, 'value']\n",
    "        timestamp = df.iloc[df.shape[0] - 1,:]['day']\n",
    "        sensebox = df.iloc[df.shape[0] - 1,:]['boxId']\n",
    "            \n",
    "        ## Trigger check\n",
    "        if pm_value > pm_threshold:\n",
    "            \n",
    "            ## Trigger notification\n",
    "            response = warning_event_response(timestamp, round(pm_value,2), sensebox)\n",
    "            print(response)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            ## PM levels are safe\n",
    "            print(str(sensebox)+\" : \"+str(timestamp)+\" : Message Received PM 2.5 Levels are safe\")\n",
    "\n",
    "    except:\n",
    "\n",
    "        ## In the begining when the consumer has just started there isn't enough data points to calculate rolling average for 3 days,\n",
    "        ## hence, this logic will fail in the initial 2 iterations and can be simply handled by a try-catch section\n",
    "        \n",
    "        pass # do nothing and continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trigger the Kafka Consumer, the infinite loop will automatically break if no message is received for more than **10 seconds**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EVENT DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5750220bed08f9680c6b4154 : 2022-01-23T15:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "5750220bed08f9680c6b4154 : 2022-01-24T16:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "5750220bed08f9680c6b4154 : 2022-01-25T17:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 25.88\n",
      "5750220bed08f9680c6b4154 : 2022-01-26T18:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 28.39\n",
      "5750220bed08f9680c6b4154 : 2022-01-27T19:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 20.99\n",
      "5750220bed08f9680c6b4154 : 2022-01-28T20:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "591f578c51d34600116a8ea5 : 2022-01-23T15:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "591f578c51d34600116a8ea5 : 2022-01-24T16:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "591f578c51d34600116a8ea5 : 2022-01-25T17:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 26.25\n",
      "591f578c51d34600116a8ea5 : 2022-01-26T18:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 133.0\n",
      "591f578c51d34600116a8ea5 : 2022-01-27T19:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 149.41\n",
      "591f578c51d34600116a8ea5 : 2022-01-28T20:00:00.000Z : !!! WARNING !!! PM 2.5 threshold exceeded with 3-Day Average of 290.63\n",
      "59ad958fd67eb50011b85f6d : 2022-01-23T15:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "59ad958fd67eb50011b85f6d : 2022-01-24T16:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "59ad958fd67eb50011b85f6d : 2022-01-25T17:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "59ad958fd67eb50011b85f6d : 2022-01-26T18:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "59ad958fd67eb50011b85f6d : 2022-01-27T19:00:00.000Z : Message Received PM 2.5 Levels are safe\n",
      "59ad958fd67eb50011b85f6d : 2022-01-28T20:00:00.000Z : Message Received PM 2.5 Levels are safe\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    ## Ifinite loop which breaks automatically based on a timer\n",
    "\n",
    "    while running:\n",
    "\n",
    "        msg = consumer.poll(timeout=10) # wait 10 seconds before exit. If no messages are received for 10 seconds, consuming will stop \n",
    "        \n",
    "        if msg is None:\n",
    "            break # if no messsages are received, exit this loop\n",
    "        if msg.error():\n",
    "\n",
    "            ## handle different errors that can come up (specific to kafka)\n",
    "\n",
    "            if msg.error().code() == KafkaError._PARTITION_EOF:\n",
    "                # End of partition event\n",
    "                sys.stderr.write('%% %s [%d] reached end at offset %d\\n' %\n",
    "                                    (msg.topic(), msg.partition(), msg.offset()))\n",
    "            elif msg.error().code() == KafkaError.UNKNOWN_TOPIC_OR_PART:\n",
    "                sys.stderr.write('Topic unknown, creating %s topic\\n' %\n",
    "                                    (topic))\n",
    "            elif msg.error():\n",
    "                raise KafkaException(msg.error())\n",
    "        else:\n",
    "            \n",
    "            ## This block is execute when everything is working fine and a message was successfully received\n",
    "\n",
    "            ## Load the message in JSON format or dictionary format\n",
    "            input = json.loads(msg.value())\n",
    "\n",
    "            ## The actual PM 2.5 value is the \"key\" of the above dictionary\n",
    "            key = list(input.keys())[0]\n",
    "            \n",
    "            ## Create a temporary dictionary with received values for each data point. Dict to Pandas conversion is easier\n",
    "            ## Each of these dicts are appended to the pandas dataframe as a row\n",
    "\n",
    "            stream = {\n",
    "                'lat': input[key][0],  # latitude of the sensor\n",
    "                'lon': input[key][1],  # longitude of the sensor\n",
    "                'day': input[key][2],  # day of the value recording\n",
    "                'value':  float(key),  # PM 2.5 Value\n",
    "                'boxId': input[key][3] # Sensebox ID\n",
    "            }\n",
    "\n",
    "            ## Append the above dict to a pandas table\n",
    "            df = df.append(stream, ignore_index = True)\n",
    "            \n",
    "            ### EVENT NOTIFICATION SECTION: START ###\n",
    "            \n",
    "            event_notification(df, pm_threshold)\n",
    "            \n",
    "            ### EVENT NOTIFICATION SECTION: END ###\n",
    "            \n",
    "        ## Commit enables processing of a message only once, meaning drops any duplicates, however, you may lose messages that\n",
    "        ## were not sent for some failure and will not be re-tried. Removing this command is possible but will require further\n",
    "        ## changes to this script to perform manual de-duplication\n",
    "        consumer.commit()\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "finally:\n",
    "    consumer.close()\n",
    "    \n",
    "    ## Note: Re-running this cell will note pull the data again as it is already pulled and the consumer is closed. You should\n",
    "    ## re-run the 'sendStream.py' file to send the data again and then restart this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>boxId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51.956168</td>\n",
       "      <td>7.651169</td>\n",
       "      <td>4.190406</td>\n",
       "      <td>2022-01-21T13:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.956168</td>\n",
       "      <td>7.651169</td>\n",
       "      <td>6.322550</td>\n",
       "      <td>2022-01-22T14:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.956168</td>\n",
       "      <td>7.651169</td>\n",
       "      <td>12.757133</td>\n",
       "      <td>2022-01-23T15:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51.956168</td>\n",
       "      <td>7.651169</td>\n",
       "      <td>26.606711</td>\n",
       "      <td>2022-01-24T16:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.956168</td>\n",
       "      <td>7.651169</td>\n",
       "      <td>38.289267</td>\n",
       "      <td>2022-01-25T17:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lat       lon      value                       day  \\\n",
       "0  51.956168  7.651169   4.190406  2022-01-21T13:00:00.000Z   \n",
       "1  51.956168  7.651169   6.322550  2022-01-22T14:00:00.000Z   \n",
       "2  51.956168  7.651169  12.757133  2022-01-23T15:00:00.000Z   \n",
       "3  51.956168  7.651169  26.606711  2022-01-24T16:00:00.000Z   \n",
       "4  51.956168  7.651169  38.289267  2022-01-25T17:00:00.000Z   \n",
       "\n",
       "                      boxId  \n",
       "0  5750220bed08f9680c6b4154  \n",
       "1  5750220bed08f9680c6b4154  \n",
       "2  5750220bed08f9680c6b4154  \n",
       "3  5750220bed08f9680c6b4154  \n",
       "4  5750220bed08f9680c6b4154  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read the output of the streamed file\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above dataframe, we have data for three different days for each of the **n** locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan                         4\n",
       "2022-01-21T13:00:00.000Z    3\n",
       "2022-01-22T14:00:00.000Z    3\n",
       "2022-01-23T15:00:00.000Z    3\n",
       "2022-01-24T16:00:00.000Z    3\n",
       "2022-01-25T17:00:00.000Z    3\n",
       "2022-01-26T18:00:00.000Z    3\n",
       "2022-01-27T19:00:00.000Z    3\n",
       "2022-01-28T20:00:00.000Z    3\n",
       "Name: day, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check how many values are present for each day\n",
    "df['day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>day</th>\n",
       "      <th>boxId</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.190406</td>\n",
       "      <td>2022-01-21T13:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "      <td>POINT (7.65117 51.95617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.322550</td>\n",
       "      <td>2022-01-22T14:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "      <td>POINT (7.65117 51.95617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.757133</td>\n",
       "      <td>2022-01-23T15:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "      <td>POINT (7.65117 51.95617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.606711</td>\n",
       "      <td>2022-01-24T16:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "      <td>POINT (7.65117 51.95617)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.289267</td>\n",
       "      <td>2022-01-25T17:00:00.000Z</td>\n",
       "      <td>5750220bed08f9680c6b4154</td>\n",
       "      <td>POINT (7.65117 51.95617)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value                       day                     boxId  \\\n",
       "0   4.190406  2022-01-21T13:00:00.000Z  5750220bed08f9680c6b4154   \n",
       "1   6.322550  2022-01-22T14:00:00.000Z  5750220bed08f9680c6b4154   \n",
       "2  12.757133  2022-01-23T15:00:00.000Z  5750220bed08f9680c6b4154   \n",
       "3  26.606711  2022-01-24T16:00:00.000Z  5750220bed08f9680c6b4154   \n",
       "4  38.289267  2022-01-25T17:00:00.000Z  5750220bed08f9680c6b4154   \n",
       "\n",
       "                   geometry  \n",
       "0  POINT (7.65117 51.95617)  \n",
       "1  POINT (7.65117 51.95617)  \n",
       "2  POINT (7.65117 51.95617)  \n",
       "3  POINT (7.65117 51.95617)  \n",
       "4  POINT (7.65117 51.95617)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Pandas to GeoPandas\n",
    "gdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.lon, df.lat))\n",
    "gdf.set_crs(epsg=4326, inplace=True, allow_override=True)\n",
    "gdf.drop(['lon','lat'], axis=1, inplace=True)\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SENSEBOX PLOTTING\n",
    "\n",
    "In this section we will plot all the senseboxes, however, based on two conditions:\n",
    "\n",
    "1. Plot senseboxes (In Green) that are live/returned values on the most recent date \n",
    "2. Plot senseboxes (In Red) that are down/did not return the values for most recent date\n",
    "\n",
    "Using this real-time map visualization we can observe which sensors are actively streaming data and what are their locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Icons for Map\n",
    "\n",
    "icon_active = AwesomeIcon(\n",
    "    name='map-marker',\n",
    "    marker_color='green',\n",
    "    icon_color='green',\n",
    "    spin=False\n",
    ")\n",
    "\n",
    "icon_inactive = AwesomeIcon(\n",
    "    name='map-marker',\n",
    "    marker_color='gray',\n",
    "    icon_color='gray',\n",
    "    spin=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['valid'] = gdf['value'].apply(lambda x: False if math.isnan(x) == True else True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get most recent date\n",
    "\n",
    "valid_boxes = gdf[gdf['valid'] == True]\n",
    "recent_date = valid_boxes['day'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>POINT (7.65117 51.95617)</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POINT (7.64522 51.96422)</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>POINT (7.63528 51.90300)</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    geometry  status\n",
       "7   POINT (7.65117 51.95617)  active\n",
       "15  POINT (7.64522 51.96422)  active\n",
       "24  POINT (7.63528 51.90300)  active"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_boxes = gdf[gdf['day'] == recent_date][['boxId','geometry']]\n",
    "active_boxes.drop_duplicates(subset=['boxId'], inplace=True)\n",
    "active_boxes = active_boxes[['geometry']]\n",
    "active_boxes['status'] = 'active'\n",
    "active_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>POINT (7.68419 51.92934)</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>POINT (7.62677 51.94632)</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>POINT (7.64146 51.95335)</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>POINT (7.64143 51.96043)</td>\n",
       "      <td>inactive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    geometry    status\n",
       "16  POINT (7.68419 51.92934)  inactive\n",
       "25  POINT (7.62677 51.94632)  inactive\n",
       "26  POINT (7.64146 51.95335)  inactive\n",
       "27  POINT (7.64143 51.96043)  inactive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inactive_boxes = gdf[gdf['valid'] == False].drop_duplicates(subset=['geometry'])[['geometry']]\n",
    "inactive_boxes['status'] = 'inactive'\n",
    "inactive_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup marker icons to display the inactive and active sensors separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a cluster of active senseboxes as points\n",
    "\n",
    "active_markers = []\n",
    "for coords in active_boxes['geometry']:\n",
    "    \n",
    "    active_markers.append(\n",
    "        Marker(location=(coords.y, coords.x), icon=icon_active, draggable=False)\n",
    "    )\n",
    "\n",
    "## Create a cluster of inactive senseboxes as points\n",
    "\n",
    "inactive_markers = []\n",
    "for coords in inactive_boxes['geometry']:\n",
    "    \n",
    "    inactive_markers.append(\n",
    "        Marker(location=(coords.y, coords.x), icon=icon_inactive, draggable=False)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d8af5eb19341e0b0dc4c6dc1807d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[51.9500023, 7.6240147], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lat = 51.9500023\n",
    "lng = 7.6240147\n",
    "\n",
    "center = (lat, lng)\n",
    "\n",
    "m = Map(center=center, zoom=11)\n",
    "\n",
    "active_boxes_cluster = MarkerCluster(\n",
    "    markers=tuple(active_markers)\n",
    ")\n",
    "\n",
    "inactive_boxes_cluster = MarkerCluster(\n",
    "    markers=tuple(inactive_markers)\n",
    ")\n",
    "\n",
    "m.add_layer(active_boxes_cluster)\n",
    "m.add_layer(inactive_boxes_cluster)\n",
    "\n",
    "display(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This marks the end of our Kafka Streaming workflow. You should now be able to see a MAP of all senseboxes locations that are active/inactive\n",
    "\n",
    "#### END OF TUTORIAL\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "1b514d23d219a1c0c56ce19fb0e1163f57dbee9d687be3151065536fbd420593"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
